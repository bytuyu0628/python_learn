{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目标\n",
    "爬取苦瓜书盘的数据，并下载图书文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from requests_html import HTMLSession\n",
    "import urllib\n",
    "import urllib.request\n",
    "import requests\n",
    "# https\n",
    "import ssl\n",
    "ssl._create_default_https_context=ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = HTMLSession()\n",
    "# 创建一个ua，绕过初级反爬\n",
    "ua = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:62.0) Gecko/20100101 Firefox/62.0'\n",
    "headers = {'User-Agent': ua}\n",
    "\n",
    "# 跳过前几页\n",
    "firstPage = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取页面最后一页的地址,str\n",
    "def get_last_page_url():\n",
    "    # 返回一个 response 对象\n",
    "    response = session.get('https://kgbook.com/list/index.html', headers=headers)\n",
    "    pages = response.html.find('div.pagenavi', first=True)\n",
    "    a_list = pages.find('a')\n",
    "    urlObject = a_list[len(a_list) - 1]\n",
    "    u = urlObject.absolute_links\n",
    "    ustr = ''.join(u)\n",
    "    return ustr;\n",
    "\n",
    "# 获取页的数量\n",
    "def get_total_pages(ustr):\n",
    "    back = ustr.split('index_')[1]\n",
    "    num = back.split('.')[0]\n",
    "    print(\"一共%s页\" % num)\n",
    "    return int(num);\n",
    "    \n",
    "# 创建页地址数组\n",
    "def get_total_page_urls(num):\n",
    "    urls = []\n",
    "    for index in range(num):\n",
    "        if index <= 0:\n",
    "            urls.append('https://kgbook.com/list/index.html')\n",
    "        else:\n",
    "            urls.append('https://kgbook.com/list/index_'+ str(index+1) +'.html')\n",
    "    return urls\n",
    "    \n",
    "# 获取当前页面数据\n",
    "def get_books_in_page(pageUrl, num):\n",
    "    print('开始分析page', str(num+1), '>>>>>>>')\n",
    "    s = session.get(pageUrl, headers=headers)\n",
    "    books = s.html.find('div.channel-item a')\n",
    "    #a_list = books.find('a')\n",
    "    return books\n",
    "    \n",
    "# 根据一个bookdetailUrl下载书籍\n",
    "def download_bookfile(pageNum, bookDetailUrl, bookname):\n",
    "    print('开始解析下载', bookname, '当前页数', str(pageNum+1), '->->->')\n",
    "    s = session.get(bookDetailUrl, headers=headers)\n",
    "    btns = s.html.find('a.button')\n",
    "    for btn in btns:\n",
    "        bookurl = ''.join(btn.absolute_links)\n",
    "        # 如果是下载链接\n",
    "        if 'GetDown' in bookurl:\n",
    "            realUrl, extendName = get_real_url(bookurl)\n",
    "            bkname = bookname + '.' + extendName\n",
    "            # 判断是不是已经存在了这本书\n",
    "            if is_exist_book(bkname):\n",
    "                print('\\033[1;31m %s 已存在，跳过下载。 \\033[0m' % bkname)\n",
    "                continue\n",
    "            downloadfile(realUrl, bkname)\n",
    "    print(bookname, '下载完毕')\n",
    "    print('-----------------------------')\n",
    "\n",
    "# 下载文件\n",
    "def downloadfile(url, filename):\n",
    "    print('开始下载文件')\n",
    "    try:\n",
    "        # r = requests.get(url)\n",
    "        path = \"books/\"+filename\n",
    "        r = requests.get(url, headers=headers)\n",
    "        with open(path,\"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        f.close()\n",
    "    except Exception:\n",
    "        print('\\033[1;31m 下载失败 \\033[0m')\n",
    "    else:\n",
    "        print(\"\\033[1;32m 下载\", filename, \"完成\\033[0m\")\n",
    "    \n",
    "# 获取重定向真实url\n",
    "def get_real_url(url):\n",
    "    print('开始获取真实下载地址')\n",
    "    # http_headers = { 'Accept': '*/*','Connection': 'keep-alive', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36'}\n",
    "    rs = requests.get(url,headers=headers)\n",
    "    print(rs.url)\n",
    "    # 获取文件的拓展名\n",
    "    words = rs.url.split('.')\n",
    "    extendName = words[len(words) - 1]\n",
    "    print('这是一个', extendName, '文件')\n",
    "    return rs.url, extendName\n",
    "\n",
    "# 目录下是否存在这本书\n",
    "def is_exist_book(bookname):\n",
    "    if os.path.exists('books/'+bookname):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一共81页\n",
      "跳过第1页\n",
      "跳过第2页\n",
      "跳过第3页\n",
      "开始分析page 4 >>>>>>>\n",
      "开始解析下载 查令十字街84号 当前页数 4 ->->->\n",
      "开始获取真实下载地址\n",
      "https://kgbook.com/d/file/201708/%E6%9F%A5%E4%BB%A4%E5%8D%81%E5%AD%97%E8%A1%9784%E5%8F%B7.azw3\n",
      "这是一个 azw3 文件\n",
      "\u001b[1;31m 查令十字街84号.azw3 已存在，跳过下载。 \u001b[0m\n",
      "开始获取真实下载地址\n"
     ]
    }
   ],
   "source": [
    "# 全部最新更新书籍\n",
    "url = get_last_page_url()\n",
    "num = get_total_pages(url)\n",
    "urls = get_total_page_urls(num)\n",
    "# 遍历page\n",
    "for index in range(len(urls)):\n",
    "    #调整起始页\n",
    "    if index < firstPage:\n",
    "        print('跳过第%s页' % str(index+1))\n",
    "        continue\n",
    "    onepage = urls[index]\n",
    "    bookset = get_books_in_page(onepage, index)\n",
    "    # 遍历单页书籍\n",
    "    for book in bookset:\n",
    "        # 属性集合\n",
    "        attrs = book.attrs\n",
    "        # 如果属性里面没有title字段，说明不是一个书籍详情的链接\n",
    "        if not 'title' in attrs.keys():\n",
    "            continue\n",
    "        title = book.text\n",
    "        bookDetailUrl = ''.join(book.absolute_links)\n",
    "        download_bookfile(index, bookDetailUrl, title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
