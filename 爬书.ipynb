{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目标\n",
    "爬取苦瓜书盘的数据，并下载图书文件。\n",
    "支持单线程与多线程爬虫\n",
    "\n",
    "![](http://881023.top/image/爬书战果.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from requests_html import HTMLSession\n",
    "import urllib\n",
    "import urllib.request\n",
    "import requests\n",
    "# https\n",
    "import ssl\n",
    "ssl._create_default_https_context=ssl._create_unverified_context\n",
    "# 线程池\n",
    "from concurrent.futures import ThreadPoolExecutor,wait,as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = HTMLSession()\n",
    "# 创建一个ua，绕过初级反爬\n",
    "ua = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:62.0) Gecko/20100101 Firefox/62.0'\n",
    "headers = {'User-Agent': ua}\n",
    "# 创建一个最大数量为3的线程池\n",
    "executor = ThreadPoolExecutor(max_workers=3)\n",
    "# 跳过前几页\n",
    "firstPage = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取页面最后一页的地址,str\n",
    "def get_last_page_url():\n",
    "    # 返回一个 response 对象\n",
    "    response = session.get('https://kgbook.com/list/index.html', headers=headers)\n",
    "    pages = response.html.find('div.pagenavi', first=True)\n",
    "    a_list = pages.find('a')\n",
    "    urlObject = a_list[len(a_list) - 1]\n",
    "    u = urlObject.absolute_links\n",
    "    ustr = ''.join(u)\n",
    "    return ustr;\n",
    "\n",
    "# 获取页的数量\n",
    "def get_total_pages(ustr):\n",
    "    back = ustr.split('index_')[1]\n",
    "    num = back.split('.')[0]\n",
    "    print(\"一共%s页\" % num)\n",
    "    return int(num);\n",
    "    \n",
    "# 创建页地址数组\n",
    "def get_total_page_urls(num):\n",
    "    urls = []\n",
    "    for index in range(num):\n",
    "        if index <= 0:\n",
    "            urls.append('https://kgbook.com/list/index.html')\n",
    "        else:\n",
    "            urls.append('https://kgbook.com/list/index_'+ str(index+1) +'.html')\n",
    "    return urls\n",
    "    \n",
    "# 获取当前页面数据\n",
    "def get_books_in_page(pageUrl, num):\n",
    "    print('开始分析page', str(num+1), '>>>>>>>')\n",
    "    s = session.get(pageUrl, headers=headers)\n",
    "    books = s.html.find('div.channel-item a')\n",
    "    #a_list = books.find('a')\n",
    "    return books\n",
    "    \n",
    "# 根据一个bookdetailUrl下载书籍\n",
    "def download_bookfile(pageNum, bookDetailUrl, bookname):\n",
    "    print('开始解析下载', bookname, '当前页数', str(pageNum+1), '->->->')\n",
    "    s = session.get(bookDetailUrl, headers=headers)\n",
    "    btns = s.html.find('a.button')\n",
    "    for btn in btns:\n",
    "        bookurl = ''.join(btn.absolute_links)\n",
    "        # 如果是下载链接\n",
    "        if 'GetDown' in bookurl:\n",
    "            realUrl, extendName = get_real_url(bookurl)\n",
    "            bkname = bookname + '.' + extendName\n",
    "            # 判断是不是已经存在了这本书\n",
    "            if is_exist_book(bkname):\n",
    "                print('\\033[1;31m %s 已存在，跳过下载。 \\033[0m' % bkname)\n",
    "                continue\n",
    "            downloadfile(realUrl, bkname)\n",
    "    print(bookname, '下载完毕')\n",
    "    print('-----------------------------')\n",
    "\n",
    "# 下载文件\n",
    "def downloadfile(url, filename):\n",
    "    print('开始下载文件')\n",
    "    try:\n",
    "        # r = requests.get(url)\n",
    "        path = \"books/\"+filename\n",
    "        r = requests.get(url, headers=headers)\n",
    "        with open(path,\"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        f.close()\n",
    "    except Exception:\n",
    "        print('\\033[1;31m 下载失败 \\033[0m')\n",
    "    else:\n",
    "        print(\"\\033[1;32m 下载\", filename, \"完成\\033[0m\")\n",
    "    \n",
    "# 获取重定向真实url\n",
    "def get_real_url(url):\n",
    "    print('开始获取真实下载地址')\n",
    "    # http_headers = { 'Accept': '*/*','Connection': 'keep-alive', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36'}\n",
    "    rs = requests.get(url,headers=headers)\n",
    "    print(rs.url)\n",
    "    # 获取文件的拓展名\n",
    "    words = rs.url.split('.')\n",
    "    extendName = words[len(words) - 1]\n",
    "    print('这是一个', extendName, '文件')\n",
    "    return rs.url, extendName\n",
    "\n",
    "# 目录下是否存在这本书\n",
    "def is_exist_book(bookname):\n",
    "    if os.path.exists('books/'+bookname):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单线程进行书籍爬取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全部最新更新书籍\n",
    "url = get_last_page_url()\n",
    "num = get_total_pages(url)\n",
    "urls = get_total_page_urls(num)\n",
    "# 遍历page\n",
    "for index in range(len(urls)):\n",
    "    #调整起始页\n",
    "    if index < firstPage:\n",
    "        print('跳过第%s页' % str(index+1))\n",
    "        continue\n",
    "    onepage = urls[index]\n",
    "    bookset = get_books_in_page(onepage, index)\n",
    "    # 遍历单页书籍\n",
    "    for book in bookset:\n",
    "        # 属性集合\n",
    "        attrs = book.attrs\n",
    "        # 如果属性里面没有title字段，说明不是一个书籍详情的链接\n",
    "        if not 'title' in attrs.keys():\n",
    "            continue\n",
    "        title = book.text\n",
    "        bookDetailUrl = ''.join(book.absolute_links)\n",
    "        download_bookfile(index, bookDetailUrl, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多线程进行数据爬取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始获取真实下载地址\n",
      "\u001b[1;32m 下载 风起陇西.pdf 完成\u001b[0m\n",
      "风起陇西 下载完毕\n",
      "-----------------------------\n",
      "开始解析下载 飞狐外传 当前页数 59 ->->->\n",
      "开始获取真实下载地址\n",
      "https://kgbook.com/d/file/201012/c939bce2a412115f3b3c0399559a0441.pdf\n",
      "这是一个 pdf 文件\n",
      "开始下载文件\n",
      "\u001b[1;32m 下载 连城诀.pdf 完成\u001b[0m\n",
      "连城诀 下载完毕\n",
      "-----------------------------\n",
      "开始解析下载 碧血剑 当前页数 59 ->->->\n",
      "开始获取真实下载地址\n",
      "https://kgbook.com/d/file/201012/9c214ce7ddb646e849c4f7e6a15078fe.pdf\n",
      "这是一个 pdf 文件\n",
      "开始下载文件\n",
      "https://kgbook.com/d/file/201012/2ca19ee3e5d35e4b06752d99c158c63b.pdf\n",
      "这是一个 pdf 文件\n",
      "开始下载文件\n",
      "\u001b[1;32m 下载 飞狐外传.pdf 完成\u001b[0m\n",
      "飞狐外传 下载完毕\n",
      "-----------------------------\n",
      "开始解析下载 闲看水浒：字缝里的梁山规则与江湖世界 当前页数 59 ->->->\n",
      "开始获取真实下载地址\n",
      "https://kgbook.com/d/file/201012/53d2293660f3d3e5ca2a5f226b0784e6.pdf\n",
      "这是一个 pdf 文件\n",
      "开始下载文件\n",
      "\u001b[1;32m 下载 笑傲江湖.pdf 完成\u001b[0m\n",
      "笑傲江湖 下载完毕\n",
      "-----------------------------\n",
      "开始解析下载 古代汉语(第四册) 当前页数 59 ->->->\n",
      "开始获取真实下载地址\n",
      "https://kgbook.com/d/file/201012/571bac77da873dcde8eea341836b1fbf.pdf\n",
      "这是一个 pdf 文件\n",
      "开始下载文件\n",
      "\u001b[1;32m 下载 闲看水浒：字缝里的梁山规则与江湖世界.pdf 完成\u001b[0m\n",
      "闲看水浒：字缝里的梁山规则与江湖世界 下载完毕\n",
      "-----------------------------\n",
      "开始解析下载 儿歌简笔画 当前页数 59 ->->->\n",
      "开始获取真实下载地址\n",
      "https://kgbook.com/d/file/201012/3c05891932692cacc11258a10f3c13e7.pdf\n",
      "这是一个 pdf 文件\n",
      "开始下载文件\n",
      "https://kgbook.com/d/file/201012/9fe07080dc0f8c0b4f1c1750875c56dd.pdf\n",
      "这是一个 pdf 文件\n",
      "开始下载文件\n",
      "\u001b[1;32m 下载 儿歌简笔画.pdf 完成\u001b[0m\n",
      "儿歌简笔画 下载完毕\n",
      "-----------------------------\n",
      "开始解析下载 寻秦记 当前页数 59 ->->->\n",
      "开始获取真实下载地址\n"
     ]
    }
   ],
   "source": [
    "# 全部最新更新书籍\n",
    "url = get_last_page_url()\n",
    "num = get_total_pages(url)\n",
    "urls = get_total_page_urls(num)\n",
    "# 遍历page\n",
    "for index in range(len(urls)):\n",
    "    #调整起始页\n",
    "    if index < firstPage:\n",
    "        print('跳过第%s页' % str(index+1))\n",
    "        continue\n",
    "    onepage = urls[index]\n",
    "    bookset = get_books_in_page(onepage, index)\n",
    "    futures = []\n",
    "    # 遍历单页书籍\n",
    "    for book in bookset:\n",
    "        # 属性集合\n",
    "        attrs = book.attrs\n",
    "        # 如果属性里面没有title字段，说明不是一个书籍详情的链接\n",
    "        if not 'title' in attrs.keys():\n",
    "            continue\n",
    "        title = book.text\n",
    "        bookDetailUrl = ''.join(book.absolute_links)\n",
    "        # 把任务加入线程池队列\n",
    "        print('把%s加入任务队列' % title)\n",
    "        future = executor.submit(download_bookfile,index,bookDetailUrl,title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
